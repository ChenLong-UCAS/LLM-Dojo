{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "file = '../download_llm/01ai/Yi-6B-Chat-4bits'\n",
    "tokenizer = AutoTokenizer.from_pretrained(file, use_fast=False, trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ced460eeb2758cf3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "LlamaTokenizer(name_or_path='../download_llm/01ai/Yi-6B-Chat-4bits', vocab_size=64000, model_max_length=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<unk>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|im_sep|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t1: AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t2: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t6: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t7: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t8: AddedToken(\"<|im_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:29:21.911952500Z",
     "start_time": "2024-01-29T15:29:21.895148100Z"
    }
   },
   "id": "2f85cae1173b9455"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[25902, 60530]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"你好啊\", add_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:41:48.354921800Z",
     "start_time": "2024-01-29T15:41:48.339293600Z"
    }
   },
   "id": "e7c2316645e15801"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'你好啊'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([25902, 60530])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:41:39.085894900Z",
     "start_time": "2024-01-29T15:41:39.070267900Z"
    }
   },
   "id": "9d670d086acf74af"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Loading an AWQ quantized model requires auto-awq library (`pip install autoawq`)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoModelForCausalLM\n\u001B[1;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat16\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m      8\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\MiniConda\\envs\\wzh\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    564\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    565\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[1;32m--> 566\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m    567\u001B[0m         pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39mmodel_args, config\u001B[38;5;241m=\u001B[39mconfig, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    568\u001B[0m     )\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    572\u001B[0m )\n",
      "File \u001B[1;32mD:\\MiniConda\\envs\\wzh\\lib\\site-packages\\transformers\\modeling_utils.py:3175\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   3172\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU is required to run AWQ quantized model.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   3174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_auto_awq_available():\n\u001B[1;32m-> 3175\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading an AWQ quantized model requires auto-awq library (`pip install autoawq`)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   3177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available():\n\u001B[0;32m   3178\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading an AWQ quantized model requires accelerate (`pip install accelerate`)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mImportError\u001B[0m: Loading an AWQ quantized model requires auto-awq library (`pip install autoawq`)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    file,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:32:08.625572400Z",
     "start_time": "2024-01-29T15:32:07.319841300Z"
    }
   },
   "id": "b2349fae7cf39769"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): QWenLMHeadModel(\n      (transformer): QWenModel(\n        (wte): Embedding(151936, 2048)\n        (drop): Dropout(p=0.0, inplace=False)\n        (rotary_emb): RotaryEmbedding()\n        (h): ModuleList(\n          (0-23): 24 x QWenBlock(\n            (ln_1): RMSNorm()\n            (attn): QWenAttention(\n              (c_attn): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=6144, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=6144, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (c_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (attn_dropout): Dropout(p=0.0, inplace=False)\n            )\n            (ln_2): RMSNorm()\n            (mlp): QWenMLP(\n              (w1): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=5504, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=5504, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (w2): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=5504, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=5504, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (c_proj): lora.Linear(\n                (base_layer): Linear(in_features=5504, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=5504, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n            )\n          )\n        )\n        (ln_f): RMSNorm()\n      )\n      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n    )\n  )\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = tokenizer.encode(\"<|im_end|>\")\n",
    "instruction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:06:17.915252600Z",
     "start_time": "2024-01-28T16:06:17.349544900Z"
    }
   },
   "id": "281f6309eef1be3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"instruction\":\"回答以下用户问题，仅输出答案。\", \"input\":\"1+1等于几?\", \"output\":\"2\"}\\n', '{\"instruction\":\"你是一个高智商人群\", \"input\":\"5+1等于几?\", \"output\":\"6\"}\\n', '{\"instruction\":\"回答以下用户问题，仅输出答案。\", \"input\":\"1+1等于几?\", \"output\":\"2\"}\\n', '{\"instruction\":\"你是一个高智商人群\", \"input\":\"5+1等于几?\", \"output\":\"6\"}\\n', '{\"instruction\":\"回答以下用户问题，仅输出答案。\", \"input\":\"1+1等于几?\", \"output\":\"2\"}\\n', '{\"instruction\":\"你是一个高智商人群\", \"input\":\"5+1等于几?\", \"output\":\"6\"}']\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'instruction': '回答以下用户问题，仅输出答案。', 'input': '1+1等于几?', 'output': '2'}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('./11.jsonl', 'r', encoding='utf8') as f:\n",
    "    data_list = f.readlines()\n",
    "print(data_list)\n",
    "data = json.loads(data_list[0])\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T09:40:11.727107900Z",
     "start_time": "2024-04-26T09:40:11.711453900Z"
    }
   },
   "id": "9d6cf82226118dc9"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m([\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m([\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m])\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "assert len([1]) == len([1,2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:37:42.580072700Z",
     "start_time": "2024-01-28T11:37:42.564781500Z"
    }
   },
   "id": "550b3233aa0d74c6"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 2, 3, 4]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "aa = a[:8]\n",
    "aa"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:43:18.102640700Z",
     "start_time": "2024-01-28T11:43:18.092635300Z"
    }
   },
   "id": "768e5291ff08fead"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "padding_len = 2 - 5\n",
    "# padding\n",
    "input_ids = [1,2,3] + [-1] * padding_len\n",
    "print(padding_len)\n",
    "print(input_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T12:18:11.269218400Z",
     "start_time": "2024-01-28T12:18:11.225824Z"
    }
   },
   "id": "1ca9d6cb5b37b384"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_json('./11.jsonl',lines=True)\n",
    "df1.to_json('./ceshi.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T12:05:54.702811100Z",
     "start_time": "2024-01-29T12:05:54.280372400Z"
    }
   },
   "id": "892426108c978492"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "14dd339bda92e1a0"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'<|System|>:You are a helpful assistant.\\n'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_format=\"<|System|>:{content}\\n\"\n",
    "system=\"You are a helpful assistant.\"\n",
    "system_text = system_format.format(content=system,stop='1111')\n",
    "system_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T11:46:58.243973100Z",
     "start_time": "2024-04-26T11:46:58.221698200Z"
    }
   },
   "id": "76c7e696efaff013"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
